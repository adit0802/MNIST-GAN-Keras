# MNIST-GAN-Keras
Generative Adversarial Networks (GANs).
### The GAN model architecture involves two sub-models:
A generator model for generating new examples and a discriminator model for classifying whether generated examples are real, from the domain, or fake, generated by the generator model.

- Generator Model that is used to generate new plausible examples from the problem domain.
- Discriminator Model that is used to classify examples as real (from the domain) or fake (generated).

### The Generator Model
- The generator model takes a fixed-length random vector as input and generates a sample in the domain.

- The vector is drawn from randomly from a Gaussian distribution, and the vector is used to seed the generative process. After training, points in this multidimensional vector space will correspond to points in the problem domain, forming a compressed representation of the data distribution.

- This vector space is referred to as a latent space, or a vector space comprised of latent variables. Latent variables, or hidden variables, are those variables that are important for a domain but are not directly observable.

- We often refer to latent variables, or a latent space, as a projection or compression of a data distribution. That is, a latent space provides a compression or high-level concepts of the observed raw data such as the input data distribution. In the case of GANs, the generator model applies meaning to points in a chosen latent space, such that new points drawn from the latent space can be provided to the generator model as input and used to generate new and different output examples.

### The Discriminator Model
- The discriminator model takes an example from the domain as input (real or generated) and predicts a binary class label of real or fake (generated).

- The real example comes from the training dataset. The generated examples are output by the generator model.

- The discriminator is a normal (and well understood) classification model.

- After the training process, the discriminator model is discarded as we are interested in the generator.

- Sometimes, the generator can be repurposed as it has learned to effectively extract features from examples in the problem domain. Some or all of the feature extraction layers can be used in transfer learning applications using the same or similar input data.

### GANs and Convolutional Neural Networks
- GANs typically work with image data and use Convolutional Neural Networks, or CNNs, as the generator and discriminator models.

- The reason for this may be both because the first description of the technique was in the field of computer vision and used CNNs and image data, and because of the remarkable progress that has been seen in recent years using CNNs more generally to achieve state-of-the-art results on a suite of computer vision tasks such as object detection and face recognition.

- Modeling image data means that the latent space, the input to the generator, provides a compressed representation of the set of images or photographs used to train the model. It also means that the generator generates new images or photographs, providing an output that can be easily viewed and assessed by developers or users of the model.

- It may be this fact above others, the ability to visually assess the quality of the generated output, that has both led to the focus of computer vision applications with CNNs and on the massive leaps in the capability of GANs as compared to other generative models, deep learning based or otherwise.

<img src = https://machinelearningmastery.com/wp-content/uploads/2019/04/Example-of-a-Conditional-Generative-Adversarial-Network-Model-Architecture.png >

### Why Generative Adversarial Networks?
- One of the many major advancements in the use of deep learning methods in domains such as computer vision is a technique called data augmentation.

- Data augmentation results in better performing models, both increasing model skill and providing a regularizing effect, reducing generalization error. It works by creating new, artificial but plausible examples from the input problem domain on which the model is trained.

- The techniques are primitive in the case of image data, involving crops, flips, zooms, and other simple transforms of existing images in the training dataset.

- Successful generative modeling provides an alternative and potentially more domain-specific approach for data augmentation. In fact, data augmentation is a simplified version of generative modeling, although it is rarely described this way.

- In complex domains or domains with a limited amount of data, generative modeling provides a path towards more training for modeling. GANs have seen much success in this use case in domains such as deep reinforcement learning.

- There are many research reasons why GANs are interesting, important, and require further study. Ian Goodfellow outlines a number of these in his 2016 conference keynote and associated technical report titled “NIPS 2016 Tutorial: Generative Adversarial Networks.”

- Among these reasons, he highlights GANs’ successful ability to model high-dimensional data, handle missing data, and the capacity of GANs to provide multi-modal outputs or multiple plausible answers.

- Perhaps the most compelling application of GANs is in conditional GANs for tasks that require the generation of new examples. Here, Goodfellow indicates three main examples:

- **Image Super-Resolution. The ability to generate high-resolution versions of input images.**
- **Creating Art. The ability to great new and artistic images, sketches, painting, and more.**
- **Image-to-Image Translation. The ability to translate photographs across domains, such as day to night, summer to winter, and more.**
- Perhaps the most compelling reason that GANs are widely studied, developed, and used is because of their success. GANs have been able to generate photos so realistic that humans are unable to tell that they are of objects, scenes, and people that do not exist in real life.
